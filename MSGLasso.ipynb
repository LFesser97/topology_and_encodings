{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zOpxppRDmsSK"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "MSGLasso.ipynb\n",
        "\n",
        "Created on Wed Nov 29 2023\n",
        "\n",
        "@author: Lukas\n",
        "\n",
        "This file runs multivariate sparse group lasso on graph dataset properties\n",
        "to predict model accuracy, following \"A Metadata-Driven Approach to Understand Graph Neural Networks\"\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "pP44as_WnDuA",
        "outputId": "e235ab06-6c01-40d7-f0e4-2b6b6b68b893"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting asgl\n",
            "  Downloading asgl-1.0.5.tar.gz (16 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: cvxpy>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from asgl) (1.3.2)\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.10/dist-packages (from asgl) (1.23.5)\n",
            "Requirement already satisfied: scikit-learn>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from asgl) (1.2.2)\n",
            "Requirement already satisfied: osqp>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from cvxpy>=1.1.0->asgl) (0.6.2.post8)\n",
            "Requirement already satisfied: ecos>=2 in /usr/local/lib/python3.10/dist-packages (from cvxpy>=1.1.0->asgl) (2.0.12)\n",
            "Requirement already satisfied: scs>=1.1.6 in /usr/local/lib/python3.10/dist-packages (from cvxpy>=1.1.0->asgl) (3.2.4)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from cvxpy>=1.1.0->asgl) (1.11.3)\n",
            "Requirement already satisfied: setuptools>65.5.1 in /usr/local/lib/python3.10/dist-packages (from cvxpy>=1.1.0->asgl) (67.7.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.23.1->asgl) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.23.1->asgl) (3.2.0)\n",
            "Requirement already satisfied: qdldl in /usr/local/lib/python3.10/dist-packages (from osqp>=0.4.1->cvxpy>=1.1.0->asgl) (0.1.7.post0)\n",
            "Building wheels for collected packages: asgl\n",
            "  Building wheel for asgl (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for asgl: filename=asgl-1.0.5-py3-none-any.whl size=16002 sha256=fe104bce724a63851f14bfb4517f08f265cc9c8057737e54c57904552577550b\n",
            "  Stored in directory: /root/.cache/pip/wheels/4b/ac/16/8caac90091e10a732feb3c240d6dcf472c4b0c7f28d2b96479\n",
            "Successfully built asgl\n",
            "Installing collected packages: asgl\n",
            "Successfully installed asgl-1.0.5\n"
          ]
        }
      ],
      "source": [
        "# install asgl\n",
        "\n",
        "!pip install asgl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "vknrUnO-nOv7"
      },
      "outputs": [],
      "source": [
        "# Import required packages\n",
        "import asgl\n",
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "6UO6WwBVnrnY"
      },
      "outputs": [],
      "source": [
        "# Define parameters grid\n",
        "lambda1 = (10.0 ** np.arange(-3, 1.51, 0.2)) # 23 possible values for lambda\n",
        "alpha = np.arange(0, 1, 0.05) # 20 possible values for alpha\n",
        "\n",
        "# Define model parameters\n",
        "model = 'lm'  # linear model\n",
        "penalization = 'sgl'  # sparse group lasso penalization\n",
        "parallel = True  # Code executed in parallel\n",
        "error_type = 'MSE'  # Error measuremente considered. MSE stands for Mean Squared Error."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QT0DOG5ionYU",
        "outputId": "ff6bfaf7-05bb-4cd1-980f-4da0edb8e011"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/cvxpy/problems/problem.py:1387: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/cvxpy/problems/problem.py:1387: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/cvxpy/problems/problem.py:1387: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/cvxpy/problems/problem.py:1387: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/cvxpy/problems/problem.py:1387: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# Define a cross validation object\n",
        "cv_class = asgl.CV(model=model, penalization=penalization, lambda1=lambda1, alpha=alpha,\n",
        "                   nfolds=5, error_type=error_type, parallel=parallel, random_state=99)\n",
        "\n",
        "# Compute error using k-fold cross validation\n",
        "error = cv_class.cross_validation(x=x, y=y, group_index=group_index)\n",
        "\n",
        "# Obtain the mean error across different folds\n",
        "error = np.mean(error, axis=1)\n",
        "\n",
        "# Select the minimum error\n",
        "minimum_error_idx = np.argmin(error)\n",
        "\n",
        "# Select the parameters associated to mininum error values\n",
        "optimal_parameters = cv_class.retrieve_parameters_value(minimum_error_idx)\n",
        "optimal_lambda = optimal_parameters.get('lambda1')\n",
        "optimal_alpha = optimal_parameters.get('alpha')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "aa9FqJ-YotM6"
      },
      "outputs": [],
      "source": [
        "# Define asgl class using optimal values\n",
        "asgl_model = asgl.ASGL(model=model, penalization=penalization, lambda1=optimal_lambda, alpha=optimal_alpha)\n",
        "\n",
        "# Split data into train / test\n",
        "train_idx, test_idx = asgl.train_test_split(nrows=x.shape[0], train_pct=0.7, random_state=1)\n",
        "\n",
        "# Solve the model\n",
        "asgl_model.fit(x=x[train_idx, :], y=y[train_idx], group_index=group_index)\n",
        "\n",
        "# Obtain betas\n",
        "final_beta_solution = asgl_model.coef_[0]\n",
        "\n",
        "# Obtain predictions\n",
        "final_prediction = asgl_model.predict(x_new=x[test_idx, :])\n",
        "\n",
        "# Obtain final errors\n",
        "final_error = asgl.error_calculator(y_true=y[test_idx], prediction_list=final_prediction, error_type=error_type)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Record Graph Properties**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# load in the data\n",
        "\n",
        "mutag = list(TUDataset(root=\"data\", name=\"MUTAG\"))\n",
        "enzymes = list(TUDataset(root=\"data\", name=\"ENZYMES\"))\n",
        "proteins = list(TUDataset(root=\"data\", name=\"PROTEINS\"))\n",
        "imdb = list(TUDataset(root=\"data\", name=\"IMDB-BINARY\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# for each dataset, create a dataframe with the graph index and the properties, \n",
        "# i.e. edge density, average degree, degree assortativity, pseudo diameter, average clustering coefficient,\n",
        "# transitivity, algebraic connectivity, curvature gap, and relative size of the largest clique\n",
        "\n",
        "def compute_edge_density(data):\n",
        "    densities = []\n",
        "    for i in tqdm.tqdm(range(len(data))):\n",
        "        edge_density = data[i].num_edges / (data[i].num_nodes * (data[i].num_nodes - 1) / 2)\n",
        "        densities.append(edge_density)\n",
        "    return densities\n",
        "\n",
        "def compute_average_degree(data):\n",
        "    average_degrees = []\n",
        "    for i in tqdm.tqdm(range(len(data))):\n",
        "        average_degree = data[i].num_edges / data[i].num_nodes\n",
        "        average_degrees.append(average_degree)\n",
        "    return average_degrees\n",
        "\n",
        "def compute_degree_assortativity(data):\n",
        "    degree_assortativities = []\n",
        "    for i in tqdm.tqdm(range(len(data))):\n",
        "        G = to_networkx(data[i])\n",
        "        degree_assortativity = nx.degree_assortativity_coefficient(G)\n",
        "        degree_assortativities.append(degree_assortativity)\n",
        "    return degree_assortativities\n",
        "\n",
        "def compute_pseudo_diameter(data):\n",
        "    pseudo_diameters = []\n",
        "    for i in tqdm.tqdm(range(len(data))):\n",
        "        G = to_networkx(data[i])\n",
        "        G = G.to_undirected()\n",
        "        if nx.is_connected(G) == False:\n",
        "            connected_components = list(nx.connected_components(G)).sort(key=len, reverse=True)\n",
        "            if connected_components is not None:\n",
        "                G = G.subgraph(connected_components[0])\n",
        "                pseudo_diameter = nx.algorithms.distance_measures.diameter(G)\n",
        "            else:\n",
        "                pseudo_diameter = 1\n",
        "        else:\n",
        "            pseudo_diameter = nx.algorithms.distance_measures.diameter(G)\n",
        "        pseudo_diameters.append(pseudo_diameter)\n",
        "    return pseudo_diameters\n",
        "\n",
        "def compute_average_clustering_coefficient(data):\n",
        "    average_clustering_coefficients = []\n",
        "    for i in tqdm.tqdm(range(len(data))):\n",
        "        G = to_networkx(data[i])\n",
        "        average_clustering_coefficient = nx.average_clustering(G)\n",
        "        average_clustering_coefficients.append(average_clustering_coefficient)\n",
        "    return average_clustering_coefficients\n",
        "\n",
        "def compute_transitivity(data):\n",
        "    transitivities = []\n",
        "    for i in tqdm.tqdm(range(len(data))):\n",
        "        G = to_networkx(data[i])\n",
        "        G.to_undirected()\n",
        "        transitivity = nx.transitivity(G) \n",
        "        transitivities.append(transitivity)\n",
        "    return transitivities\n",
        "\n",
        "def compute_algebraic_connectivity(data):\n",
        "    connectivities = []\n",
        "    for i in tqdm.tqdm(range(len(data))):\n",
        "        G = to_networkx(data[i]).to_undirected()\n",
        "        algebraic_connectivity = nx.algebraic_connectivity(G)\n",
        "        connectivities.append(algebraic_connectivity)\n",
        "    return connectivities\n",
        "\n",
        "def compute_curvature_gap(data):\n",
        "    curvature_gaps = []\n",
        "    for i in tqdm.tqdm(range(len(data))):\n",
        "        try:\n",
        "            G = to_networkx(data[i])\n",
        "            rc = OllivierRicci(G, alpha=0.5, verbose=\"ERROR\")\n",
        "            rc.compute_ricci_curvature()\n",
        "\n",
        "            curvature = np.array(list(rc.G.nodes(data=\"ricciCurvature\")))\n",
        "            curvature = curvature[:, 1].reshape(-1, 1)\n",
        "            gmm = GaussianMixture(n_components=2, covariance_type=\"full\", random_state=0).fit(curvature)\n",
        "\n",
        "            curvature_gap = abs(gmm.means_[0] - gmm.means_[1]) / np.sqrt(0.5 * (gmm.covariances_[0] ** 2 + gmm.covariances_[1] ** 2))\n",
        "            curvature_gaps.append(curvature_gap)\n",
        "        except:\n",
        "            curvature_gaps.append(0)\n",
        "    return curvature_gaps\n",
        "\n",
        "def compute_max_clique(data):\n",
        "    max_cliques = []\n",
        "    for i in tqdm.tqdm(range(len(data))):\n",
        "        G = to_networkx(data[i]).to_undirected()\n",
        "        max_clique = nx.algorithms.clique.graph_clique_number(G)\n",
        "        max_cliques.append(max_clique)\n",
        "    return max_cliques\n",
        "    \n",
        "\n",
        "# MUTAG\n",
        "mutag_df = pd.DataFrame(columns=['graph_index', 'edge_density', 'avg_degree', 'degree_assortativity', 'pseudo_diameter', 'avg_clustering_coeff', 'transitivity', 'algebraic_connectivity', 'curvature_gap', 'rel_size_largest_clique'])\n",
        "mutag_df['graph_index'] = range(len(mutag))\n",
        "mutag_df['edge_density'] = compute_edge_density(mutag)\n",
        "mutag_df['avg_degree'] = compute_average_degree(mutag)\n",
        "mutag_df['degree_assortativity'] = compute_degree_assortativity(mutag)\n",
        "mutag_df['pseudo_diameter'] = compute_pseudo_diameter(mutag)\n",
        "mutag_df['avg_clustering_coeff'] = compute_average_clustering_coefficient(mutag)\n",
        "mutag_df['transitivity'] = compute_transitivity(mutag)\n",
        "mutag_df['algebraic_connectivity'] = compute_algebraic_connectivity(mutag)\n",
        "mutag_df['curvature_gap'] = compute_curvature_gap(mutag)\n",
        "mutag_df['rel_size_largest_clique'] = compute_max_clique(mutag)\n",
        "\n",
        "# ENZYMES\n",
        "enzymes_df = pd.DataFrame(columns=['graph_index', 'edge_density', 'avg_degree', 'degree_assortativity', 'pseudo_diameter', 'avg_clustering_coeff', 'transitivity', 'algebraic_connectivity', 'curvature_gap', 'rel_size_largest_clique'])\n",
        "enzymes_df['graph_index'] = range(len(enzymes))\n",
        "enzymes_df['edge_density'] = compute_edge_density(enzymes)\n",
        "enzymes_df['avg_degree'] = compute_average_degree(enzymes)\n",
        "enzymes_df['degree_assortativity'] = compute_degree_assortativity(enzymes)\n",
        "enzymes_df['pseudo_diameter'] = compute_pseudo_diameter(enzymes)\n",
        "enzymes_df['avg_clustering_coeff'] = compute_average_clustering_coefficient(enzymes)\n",
        "enzymes_df['transitivity'] = compute_transitivity(enzymes)\n",
        "enzymes_df['algebraic_connectivity'] = compute_algebraic_connectivity(enzymes)\n",
        "enzymes_df['curvature_gap'] = compute_curvature_gap(enzymes)\n",
        "enzymes_df['rel_size_largest_clique'] = compute_max_clique(enzymes)\n",
        "\n",
        "# PROTEINS\n",
        "proteins_df = pd.DataFrame(columns=['graph_index', 'edge_density', 'avg_degree', 'degree_assortativity', 'pseudo_diameter', 'avg_clustering_coeff', 'transitivity', 'algebraic_connectivity', 'curvature_gap', 'rel_size_largest_clique'])\n",
        "proteins_df['graph_index'] = range(len(proteins))\n",
        "proteins_df['edge_density'] = compute_edge_density(proteins)\n",
        "proteins_df['avg_degree'] = compute_average_degree(proteins)\n",
        "proteins_df['degree_assortativity'] = compute_degree_assortativity(proteins)\n",
        "proteins_df['pseudo_diameter'] = compute_pseudo_diameter(proteins)\n",
        "proteins_df['avg_clustering_coeff'] = compute_average_clustering_coefficient(proteins)\n",
        "proteins_df['transitivity'] = compute_transitivity(proteins)\n",
        "proteins_df['algebraic_connectivity'] = compute_algebraic_connectivity(proteins)\n",
        "proteins_df['curvature_gap'] = compute_curvature_gap(proteins)\n",
        "proteins_df['rel_size_largest_clique'] = compute_max_clique(proteins)\n",
        "\n",
        "# IMDB\n",
        "imdb_df = pd.DataFrame(columns=['graph_index', 'edge_density', 'avg_degree', 'degree_assortativity', 'pseudo_diameter', 'avg_clustering_coeff', 'transitivity', 'algebraic_connectivity', 'curvature_gap', 'rel_size_largest_clique'])\n",
        "imdb_df['graph_index'] = range(len(imdb))\n",
        "imdb_df['edge_density'] = compute_edge_density(imdb)\n",
        "imdb_df['avg_degree'] = compute_average_degree(imdb)\n",
        "imdb_df['degree_assortativity'] = compute_degree_assortativity(imdb)\n",
        "imdb_df['pseudo_diameter'] = compute_pseudo_diameter(imdb)\n",
        "imdb_df['avg_clustering_coeff'] = compute_average_clustering_coefficient(imdb)\n",
        "imdb_df['transitivity'] = compute_transitivity(imdb)\n",
        "imdb_df['algebraic_connectivity'] = compute_algebraic_connectivity(imdb)\n",
        "imdb_df['curvature_gap'] = compute_curvature_gap(imdb)\n",
        "imdb_df['rel_size_largest_clique'] = compute_max_clique(imdb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# save all dataframes to csv files\n",
        "mutag_df.to_csv('mutag.csv')\n",
        "enzymes_df.to_csv('enzymes.csv')\n",
        "proteins_df.to_csv('proteins.csv')\n",
        "imdb_df.to_csv('imdb.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# load in the accuracy dictionaryies and add them to the dataframes\n",
        "\n",
        "# MUTAG\n",
        "with open('results/mutag_graph_dict.pickle', 'rb') as handle:\n",
        "    mutag_accs = pickle.load(handle)\n",
        "\n",
        "mutags_avgs = {}\n",
        "for key in mutag_accs.keys():\n",
        "    mutags_avgs[key] = np.mean(mutag_accs[key])\n",
        "\n",
        "mutag_df['accuracy'] = mutag_df['graph_index'].map(mutags_avgs)\n",
        "\n",
        "# ENZYMES\n",
        "with open('results/enzymes_graph_dict.pickle', 'rb') as handle:\n",
        "    enzymes_accs = pickle.load(handle)\n",
        "\n",
        "enzymes_avgs = {}\n",
        "for key in enzymes_accs.keys():\n",
        "    enzymes_avgs[key] = np.mean(enzymes_accs[key])\n",
        "\n",
        "enzymes_df['accuracy'] = enzymes_df['graph_index'].map(enzymes_avgs)\n",
        "\n",
        "# PROTEINS\n",
        "with open('results/proteins_graph_dict.pickle', 'rb') as handle:\n",
        "    proteins_accs = pickle.load(handle)\n",
        "\n",
        "proteins_avgs = {}\n",
        "for key in proteins_accs.keys():\n",
        "    proteins_avgs[key] = np.mean(proteins_accs[key])\n",
        "\n",
        "proteins_df['accuracy'] = proteins_df['graph_index'].map(proteins_avgs)\n",
        "\n",
        "# IMDB\n",
        "with open('results/imdb_graph_dict.pickle', 'rb') as handle:\n",
        "    imdb_accs = pickle.load(handle)\n",
        "\n",
        "imdb_avgs = {}\n",
        "for key in imdb_accs.keys():\n",
        "    imdb_avgs[key] = np.mean(imdb_accs[key])\n",
        "\n",
        "imdb_df['accuracy'] = imdb_df['graph_index'].map(imdb_avgs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EWWk0IEkpyAJ"
      },
      "source": [
        "**Regression**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# set hyperparameters\n",
        "\n",
        "alpha_opt = 0.5\n",
        "lambda_opt = 0.002"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# run regression with accuracy as the target variable and the properties as the features\n",
        "\n",
        "# MUTAG\n",
        "x = mutag_df[['edge_density', 'avg_degree', 'degree_assortativity', 'pseudo_diameter', 'avg_clustering_coeff', 'transitivity', 'algebraic_connectivity', 'curvature_gap', 'rel_size_largest_clique']].to_numpy()\n",
        "y = mutag_df['accuracy'].to_numpy()\n",
        "group_index = np.array([1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
        "\n",
        "# standardize the data by subtracting the mean and dividing by the standard deviation\n",
        "x_standardized = (x - np.mean(x, axis=0)) / np.std(x, axis=0)\n",
        "\n",
        "# fit the model\n",
        "\n",
        "model = asgl.ASGL(model='lm', penalization='sgl', lambda1=lambda_opt, alpha=alpha_opt)\n",
        "model.fit(x=x_standardized, y=y, group_index=group_index)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lJDUz7K2uhQ6",
        "outputId": "4aae4de2-0bd1-483d-9f0b-eaf9b490688b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([ 2.64046511e+02,  0.00000000e+00,  1.24063100e+00,  4.09944460e+00,\n",
              "       -1.23699372e+01,  1.18208572e+02,  2.70692476e+01,  3.44738482e+01,\n",
              "       -1.86345734e-01, -4.87576259e+01,  2.13417824e+02,  0.00000000e+00,\n",
              "       -1.42752151e+02,  9.38657064e+01,  1.02056033e+02, -2.46636576e+02])"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# get the coefficients\n",
        "betas = model.coef_[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# get the predictions\n",
        "predictions = model.predict(x_new=x_standardized)\n",
        "\n",
        "# get the errors\n",
        "error = asgl.error_calculator(y_true=y, prediction_list=predictions, error_type='MSE')\n",
        "\n",
        "# plot the predicted accuracy and the actual accuracy on each graph in MUTAG\n",
        "plt.scatter(range(len(predictions)), predictions, label='Predicted Accuracy')\n",
        "plt.scatter(range(len(predictions)), y, label='Actual Accuracy')\n",
        "plt.xlabel('Graph Index')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.title('MUTAG Accuracy Predictions')\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
